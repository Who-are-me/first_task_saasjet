{'text': '- So welcome everyone to CS231n.', 'start': 7.641, 'duration': 2.667} {'text': "I'm super excited to\noffer this class again", 'start': 11.762, 'duration': 2.473} {'text': 'for the third time.', 'start': 14.235, 'duration': 1.272} {'text': 'It seems that every\ntime we offer this class', 'start': 15.507, 'duration': 2.061} {'text': "it's growing exponentially\nunlike most things in the world.", 'start': 17.568, 'duration': 3.955} {'text': "This is the third time\nwe're teaching this class.", 'start': 21.523, 'duration': 2.911} {'text': 'The first time we had 150 students.', 'start': 24.434, 'duration': 2.032} {'text': 'Last year, we had 350\nstudents, so it doubled.', 'start': 26.466, 'duration': 2.534} {'text': "This year we've doubled\nagain to about 730 students", 'start': 29.0, 'duration': 3.852} {'text': 'when I checked this morning.', 'start': 32.852, 'duration': 1.954} {'text': 'So anyone who was not able\nto fit into the lecture hall', 'start': 34.806, 'duration': 3.622} {'text': 'I apologize.', 'start': 38.428, 'duration': 1.666} {'text': 'But, the videos will be\nup on the SCPD website', 'start': 40.094, 'duration': 3.095} {'text': 'within about two hours.', 'start': 43.189, 'duration': 1.742} {'text': "So if you weren't able to come today,", 'start': 44.931, 'duration': 1.969} {'text': 'then you can still check it\nout within a couple hours.', 'start': 46.9, 'duration': 3.989} {'text': 'So this class CS231n is\nreally about computer vision.', 'start': 50.889, 'duration': 4.187} {'text': 'And, what is computer vision?', 'start': 55.076, 'duration': 2.336} {'text': 'Computer vision is really\nthe study of visual data.', 'start': 57.412, 'duration': 2.729} {'text': "Since there's so many people\nenrolled in this class,", 'start': 60.141, 'duration': 2.437} {'text': "I think I probably don't\nneed to convince you", 'start': 62.578, 'duration': 1.944} {'text': 'that this is an important problem,', 'start': 64.522, 'duration': 1.697} {'text': "but I'm still going to\ntry to do that anyway.", 'start': 66.219, 'duration': 3.813} {'text': 'The amount of visual data in our world', 'start': 70.032, 'duration': 1.863} {'text': 'has really exploded to a ridiculous degree', 'start': 71.895, 'duration': 2.278} {'text': 'in the last couple of years.', 'start': 74.173, 'duration': 1.588} {'text': 'And, this is largely a\nresult of the large number', 'start': 75.761, 'duration': 1.852} {'text': 'of sensors in the world.', 'start': 77.613, 'duration': 2.785} {'text': 'Probably most of us in this room', 'start': 80.398, 'duration': 1.361} {'text': 'are carrying around smartphones,', 'start': 81.759, 'duration': 1.305} {'text': 'and each smartphone has one, two,', 'start': 83.064, 'duration': 1.94} {'text': 'or maybe even three cameras on it.', 'start': 85.004, 'duration': 1.985} {'text': "So I think on average\nthere's even more cameras", 'start': 86.989, 'duration': 1.985} {'text': 'in the world than there are people.', 'start': 88.974, 'duration': 2.14} {'text': 'And, as a result of all of these sensors,', 'start': 91.114, 'duration': 1.651} {'text': "there's just a crazy large, massive amount", 'start': 92.765, 'duration': 2.606} {'text': 'of visual data being produced\nout there in the world', 'start': 95.371, 'duration': 2.153} {'text': 'each day.', 'start': 97.524, 'duration': 0.984} {'text': 'So one statistic that I\nreally like to kind of put', 'start': 98.508, 'duration': 2.731} {'text': 'this in perspective is a 2015 study', 'start': 101.239, 'duration': 2.619} {'text': 'from CISCO that estimated that by 2017', 'start': 103.858, 'duration': 3.167} {'text': 'which is where we are now that roughly 80%', 'start': 108.919, 'duration': 2.865} {'text': 'of all traffic on the\ninternet would be video.', 'start': 111.784, 'duration': 2.7} {'text': 'This is not even counting all the images', 'start': 114.484, 'duration': 3.59} {'text': 'and other types of visual data on the web.', 'start': 118.074, 'duration': 2.451} {'text': 'But, just from a pure\nnumber of bits perspective,', 'start': 120.525, 'duration': 3.355} {'text': 'the majority of bits\nflying around the internet', 'start': 123.88, 'duration': 2.122} {'text': 'are actually visual data.', 'start': 126.002, 'duration': 1.474} {'text': "So it's really critical\nthat we develop algorithms", 'start': 127.476, 'duration': 2.071} {'text': 'that can utilize and understand this data.', 'start': 129.547, 'duration': 3.61} {'text': "However, there's a\nproblem with visual data,", 'start': 133.157, 'duration': 2.213} {'text': "and that's that it's\nreally hard to understand.", 'start': 135.37, 'duration': 2.443} {'text': 'Sometimes we call visual\ndata the dark matter', 'start': 137.813, 'duration': 3.0} {'text': 'of the internet in analogy\nwith dark matter in physics.', 'start': 140.813, 'duration': 3.713} {'text': 'So for those of you who have\nheard of this in physics', 'start': 144.526, 'duration': 2.911} {'text': 'before, dark matter accounts\nfor some astonishingly large', 'start': 147.437, 'duration': 3.743} {'text': 'fraction of the mass in the universe,', 'start': 151.18, 'duration': 2.197} {'text': 'and we know about it due to the existence', 'start': 153.377, 'duration': 1.79} {'text': 'of gravitational pulls on\nvarious celestial bodies', 'start': 155.167, 'duration': 3.126} {'text': "and what not, but we\ncan't directly observe it.", 'start': 158.293, 'duration': 2.242} {'text': 'And, visual data on the\ninternet is much the same', 'start': 160.535, 'duration': 2.303} {'text': 'where it comprises the majority of bits', 'start': 162.838, 'duration': 2.65} {'text': "flying around the internet,\nbut it's very difficult", 'start': 165.488, 'duration': 3.676} {'text': 'for algorithms to actually\ngo in and understand', 'start': 169.164, 'duration': 2.149} {'text': 'and see what exactly is\ncomprising all the visual data', 'start': 171.313, 'duration': 2.909} {'text': 'on the web.', 'start': 174.222, 'duration': 1.463} {'text': 'Another statistic that I\nlike is that of Youtube.', 'start': 175.685, 'duration': 2.781} {'text': 'So roughly every second of clock time', 'start': 178.466, 'duration': 3.843} {'text': "that happens in the world,\nthere's something like five hours", 'start': 182.309, 'duration': 2.994} {'text': 'of video being uploaded to Youtube.', 'start': 185.303, 'duration': 2.443} {'text': 'So if we just sit here and count,', 'start': 187.746, 'duration': 1.559} {'text': "one, two, three, now there's 15 more hours", 'start': 189.305, 'duration': 3.5} {'text': 'of video on Youtube.', 'start': 193.929, 'duration': 1.667} {'text': "Google has a lot of\nemployees, but there's no way", 'start': 197.076, 'duration': 1.748} {'text': 'that they could ever\nhave an employee sit down', 'start': 198.824, 'duration': 2.395} {'text': 'and watch and understand\nand annotate every video.', 'start': 201.219, 'duration': 2.927} {'text': 'So if they want to catalog and serve you', 'start': 204.146, 'duration': 2.71} {'text': 'relevant videos and maybe\nmonetize by putting ads', 'start': 206.856, 'duration': 2.505} {'text': "on those videos, it's really\ncrucial that we develop", 'start': 209.361, 'duration': 2.696} {'text': 'technologies that can dive in\nand automatically understand', 'start': 212.057, 'duration': 2.746} {'text': 'the content of visual data.', 'start': 214.803, 'duration': 2.25} {'text': 'So this field of computer vision is', 'start': 218.649, 'duration': 2.73} {'text': 'truly an interdisciplinary\nfield, and it touches', 'start': 221.379, 'duration': 2.71} {'text': 'on many different areas of science', 'start': 224.089, 'duration': 1.775} {'text': 'and engineering and technology.', 'start': 225.864, 'duration': 1.7} {'text': "So obviously, computer vision's\nthe center of the universe,", 'start': 227.564, 'duration': 3.258} {'text': 'but sort of as a constellation of fields', 'start': 230.822, 'duration': 3.092} {'text': 'around computer vision, we\ntouch on areas like physics', 'start': 233.914, 'duration': 2.539} {'text': 'because we need to understand\noptics and image formation', 'start': 236.453, 'duration': 2.965} {'text': 'and how images are\nactually physically formed.', 'start': 239.418, 'duration': 2.366} {'text': 'We need to understand\nbiology and psychology', 'start': 241.784, 'duration': 2.211} {'text': 'to understand how animal\nbrains physically see', 'start': 243.995, 'duration': 3.884} {'text': 'and process visual information.', 'start': 247.879, 'duration': 2.015} {'text': 'We of course draw a lot\non computer science,', 'start': 249.894, 'duration': 2.151} {'text': 'mathematics, and engineering\nas we actually strive', 'start': 252.045, 'duration': 2.26} {'text': 'to build computer systems that implement', 'start': 254.305, 'duration': 2.65} {'text': 'our computer vision algorithms.', 'start': 256.955, 'duration': 2.685} {'text': "So a little bit more about\nwhere I'm coming from", 'start': 259.64, 'duration': 2.955} {'text': 'and about where the teaching\nstaff of this course', 'start': 262.595, 'duration': 2.39} {'text': 'is coming from.', 'start': 264.985, 'duration': 1.007} {'text': 'Me and my co-instructor\nSerena are both PHD students', 'start': 265.992, 'duration': 4.73} {'text': 'in the Stanford Vision Lab which is headed', 'start': 270.722, 'duration': 2.884} {'text': 'by professor Fei-Fei Li,\nand our lab really focuses', 'start': 273.606, 'duration': 3.578} {'text': 'on machine learning and\nthe computer science side', 'start': 277.184, 'duration': 2.756} {'text': 'of things.', 'start': 279.94, 'duration': 1.244} {'text': 'I work a little bit more\non language and vision.', 'start': 281.184, 'duration': 2.124} {'text': "I've done some projects in that.", 'start': 283.308, 'duration': 1.592} {'text': 'And, other folks in our group have worked', 'start': 284.9, 'duration': 1.758} {'text': 'a little bit on the neuroscience\nand cognitive science', 'start': 286.658, 'duration': 1.867} {'text': 'side of things.', 'start': 288.525, 'duration': 1.25} {'text': 'So as a bit of introduction,\nyou might be curious', 'start': 292.541, 'duration': 1.863} {'text': 'about how this course relates\nto other courses at Stanford.', 'start': 294.404, 'duration': 3.153} {'text': 'So we kind of assume a basic\nintroductory understanding', 'start': 297.557, 'duration': 3.851} {'text': 'of computer vision.', 'start': 301.408, 'duration': 1.44} {'text': "So if you're kind of an undergrad,", 'start': 302.848, 'duration': 1.939} {'text': "and you've never seen\ncomputer vision before,", 'start': 304.787, 'duration': 2.139} {'text': "maybe you should've taken\nCS131 which was offered", 'start': 306.926, 'duration': 2.772} {'text': 'earlier this year by Fei-Fei\nand Juan Carlos Niebles.', 'start': 309.698, 'duration': 4.531} {'text': 'There was a course taught last quarter', 'start': 314.229, 'duration': 3.132} {'text': 'by Professor Chris\nManning and Richard Socher', 'start': 317.361, 'duration': 3.475} {'text': 'about the intersection of deep learning', 'start': 320.836, 'duration': 1.869} {'text': 'and natural language processing.', 'start': 322.705, 'duration': 2.22} {'text': 'And, I imagine a number of\nyou may have taken that course', 'start': 324.925, 'duration': 2.587} {'text': 'last quarter.', 'start': 327.512, 'duration': 1.083} {'text': "There'll be some overlap\nbetween this course and that,", 'start': 331.482, 'duration': 2.303} {'text': "but we're really focusing\non the computer vision", 'start': 333.785, 'duration': 1.984} {'text': 'side of thing, and really\nfocusing all of our motivation', 'start': 335.769, 'duration': 3.092} {'text': 'in computer vision.', 'start': 338.861, 'duration': 1.583} {'text': 'Also concurrently taught this quarter', 'start': 341.361, 'duration': 1.717} {'text': 'is CS231a taught by\nProfessor Silvio Savarese.', 'start': 343.078, 'duration': 4.3} {'text': 'And, CS231a really focuses\nis a more all encompassing', 'start': 347.378, 'duration': 4.928} {'text': 'computer vision course.', 'start': 352.306, 'duration': 1.704} {'text': "It's focusing on things\nlike 3D reconstruction,", 'start': 354.01, 'duration': 3.559} {'text': 'on matching and robotic vision,', 'start': 357.569, 'duration': 2.327} {'text': "and it's a bit more all encompassing", 'start': 359.896, 'duration': 1.516} {'text': 'with regards to vision than our course.', 'start': 361.412, 'duration': 2.401} {'text': 'And, this course, CS231n, really focuses', 'start': 363.813, 'duration': 2.834} {'text': 'on a particular class\nof algorithms revolving', 'start': 366.647, 'duration': 2.711} {'text': 'around neural networks and\nespecially convolutional', 'start': 369.358, 'duration': 2.564} {'text': 'neural networks and their applications', 'start': 371.922, 'duration': 1.864} {'text': 'to various visual recognition tasks.', 'start': 373.786, 'duration': 2.442} {'text': "Of course, there's also a number", 'start': 376.228, 'duration': 1.497} {'text': 'of seminar courses that are taught,', 'start': 377.725, 'duration': 1.453} {'text': "and you'll have to check the syllabus", 'start': 379.178, 'duration': 1.976} {'text': 'and course schedule for\nmore details on those', 'start': 381.154, 'duration': 3.477} {'text': "'cause they vary a bit each year.", 'start': 384.631, 'duration': 3.236} {'text': 'So this lecture is normally given', 'start': 387.867, 'duration': 2.047} {'text': 'by Professor Fei-Fei Li.', 'start': 389.914, 'duration': 1.758} {'text': "Unfortunately, she wasn't\nable to be here today,", 'start': 391.672, 'duration': 2.502} {'text': 'so instead for the majority of the lecture', 'start': 394.174, 'duration': 2.265} {'text': "we're going to tag team a little bit.", 'start': 396.439, 'duration': 2.024} {'text': 'She actually recorded a\nbit of pre-recorded audio', 'start': 398.463, 'duration': 3.533} {'text': 'describing to you the\nhistory of computer vision', 'start': 401.996, 'duration': 2.776} {'text': 'because this class is a\ncomputer vision course,', 'start': 404.772, 'duration': 3.457} {'text': "and it's very critical and\nimportant that you understand", 'start': 408.229, 'duration': 2.227} {'text': 'the history and the context\nof all the existing work', 'start': 410.456, 'duration': 2.833} {'text': 'that led us to these developments', 'start': 413.289, 'duration': 1.894} {'text': 'of convolutional neural\nnetworks as we know them today.', 'start': 415.183, 'duration': 2.817} {'text': "I'll let virtual Fei-Fei take over", 'start': 418.5, 'duration': 1.5} {'text': '[laughing]', 'start': 420.398, 'duration': 1.517} {'text': 'and give you a brief\nintroduction to the history', 'start': 421.915, 'duration': 1.885} {'text': 'of computer vision.', 'start': 424.0, 'duration': 1.5} {'text': "Okay let's start with today's agenda. \nSo we have two topics to cover one is a", 'start': 428.61, 'duration': 6.699} {'text': 'brief history of computer vision and the\nother one is the overview of our course', 'start': 435.309, 'duration': 5.311} {'text': "CS 231 so we'll start with a very\nbrief history of where vision comes", 'start': 440.62, 'duration': 7.919} {'text': 'from when did computer vision start and\nwhere we are today. The history the', 'start': 448.54, 'duration': 7.56} {'text': 'history of vision can go back many many\nyears ago in fact about 543 million', 'start': 456.1, 'duration': 8.67} {'text': 'years ago. What was life like during that\ntime? Well the earth was mostly water', 'start': 464.77, 'duration': 6.03} {'text': 'there were a few species of animals\nfloating around in the ocean and life', 'start': 470.92, 'duration': 7.38} {'text': "was very chill. Animals didn't move around\nmuch there they don't have eyes or", 'start': 478.3, 'duration': 5.43} {'text': "anything when food swims by they grab\nthem if the food didn't swim by they", 'start': 483.73, 'duration': 5.91} {'text': 'just float around but something really\nremarkable happened around 540 million', 'start': 489.64, 'duration': 7.5} {'text': 'years ago. From fossil studies zoologists\nfound out within a very short period of', 'start': 497.14, 'duration': 8.369} {'text': 'time —  ten million years — the number of\nanimal species just exploded. It went', 'start': 505.509, 'duration': 8.311} {'text': 'from a few of them to hundreds of\nthousands and that was strange — what caused this?', 'start': 513.82, 'duration': 7.68} {'text': 'There were many theories but for many\nyears it was a mystery evolutionary', 'start': 521.5, 'duration': 6.42} {'text': "biologists call this evolution's Big Bang.\nA few years ago an Australian zoologist", 'start': 527.92, 'duration': 7.62} {'text': 'called Andrew Parker proposed one of the\nmost convincing theory from the studies', 'start': 535.54, 'duration': 5.759} {'text': 'of fossils\nhe discovered around 540 million years', 'start': 541.299, 'duration': 5.731} {'text': 'ago the first animals developed eyes and\nthe onset of vision started this', 'start': 547.03, 'duration': 12.28} {'text': 'explosive speciation phase. Animals can\nsuddenly see; once you can see life', 'start': 559.31, 'duration': 7.3} {'text': 'becomes much more proactive. Some\npredators went after prey and prey', 'start': 566.61, 'duration': 5.97} {'text': 'have to escape from predators so the\nevolution or onset of vision started a', 'start': 572.58, 'duration': 7.4} {'text': 'evolutionary arms race and animals had\nto evolve quickly in order to survive as', 'start': 579.98, 'duration': 6.88} {'text': 'a species so that was the beginning of\nvision in animals after 540 million', 'start': 586.86, 'duration': 8.01} {'text': 'years vision has developed into the\nbiggest sensory system of almost all', 'start': 594.87, 'duration': 6.51} {'text': 'animals especially intelligent animals\nin humans we have almost 50% of the', 'start': 601.38, 'duration': 8.28} {'text': 'neurons in our cortex involved in visual\nprocessing it is the biggest sensory', 'start': 609.66, 'duration': 5.79} {'text': 'system that enables us to survive, work,\nmove around, manipulate things,', 'start': 615.45, 'duration': 7.14} {'text': 'communicate, entertain, and many things.\nThe vision is really important for', 'start': 622.59, 'duration': 7.14} {'text': 'animals and especially intelligent\nanimals. So that was a quick story of', 'start': 629.73, 'duration': 9.2} {'text': 'biological vision. What about humans, the\nhistory of humans making mechanical', 'start': 638.93, 'duration': 9.399} {'text': 'vision or cameras? Well one of the early\ncameras that we know today is from the', 'start': 648.329, 'duration': 8.121} {'text': '1600s, the Renaissance period of time,\ncamera obscura and this is a camera', 'start': 656.45, 'duration': 7.96} {'text': "based on pinhole camera theories. It's\nvery similar to, it's very similar to the", 'start': 664.41, 'duration': 9.32} {'text': 'to the early eyes that animals developed\nwith a hole that collects lights', 'start': 673.73, 'duration': 7.66} {'text': 'and then a plane in the back of the\ncamera that collects the information and', 'start': 681.39, 'duration': 6.63} {'text': 'project the imagery. So\nas cameras evolved, today we have cameras', 'start': 688.02, 'duration': 8.54} {'text': 'everywhere this is one of the most\npopular sensors people use from', 'start': 696.56, 'duration': 4.35} {'text': 'smartphones to to other sensors. In the\nmean time biologists started', 'start': 700.91, 'duration': 8.13} {'text': 'studying the mechanism of vision. One of\nthe most influential work in both human', 'start': 709.04, 'duration': 7.47} {'text': 'vision where animal vision as well as\nthat inspired computer vision is the', 'start': 716.51, 'duration': 6.18} {'text': 'work done by Hubel and Wiesel in the 50s\nand 60s using electrophysiology.', 'start': 722.69, 'duration': 8.16} {'text': 'What they were asking, the question is "what was the visual processing mechanism like', 'start': 730.85, 'duration': 7.32} {'text': 'in primates, in mammals" so they chose\nto study cat brain which is more or less', 'start': 738.17, 'duration': 8.43} {'text': 'similar to human brain from a visual\nprocessing point of view. What they did', 'start': 746.6, 'duration': 5.49} {'text': 'is to stick some electrodes in the back\nof the cat brain which is where the', 'start': 752.09, 'duration': 5.4} {'text': 'primary visual cortex area is and then\nlook at what stimuli makes the neurons', 'start': 757.49, 'duration': 8.34} {'text': 'in the in the back in the primary visual\ncortex of cat brain respond excitedly', 'start': 765.83, 'duration': 7.14} {'text': 'what they learned is that there are many\ntypes of cells in the, in the primary', 'start': 772.97, 'duration': 7.41} {'text': 'visual cortex part of the the cat brain\nbut one of the most important cell is', 'start': 780.38, 'duration': 5.25} {'text': 'the simple cells they respond to\noriented edges when they move in certain', 'start': 785.63, 'duration': 6.45} {'text': 'directions. Of course there are also more\ncomplex cells but by and large what they', 'start': 792.08, 'duration': 6.33} {'text': 'discovered is visual processing starts\nwith simple structure of the visual world,', 'start': 798.41, 'duration': 7.65} {'text': 'oriented edges and as information\nmoves along the visual processing', 'start': 806.06, 'duration': 6.15} {'text': 'pathway the brain builds up the\ncomplexity of the visual information', 'start': 812.21, 'duration': 6.35} {'text': 'until it can recognize the complex\nvisual world. So the history of', 'start': 818.56, 'duration': 7.72} {'text': 'computer vision also starts around early\n60s. Block World is a set of work', 'start': 826.28, 'duration': 8.79} {'text': 'published by Larry Roberts which is\nwidely known as one of the first,', 'start': 835.07, 'duration': 5.34} {'text': 'probably the first PhD thesis of\ncomputer vision where the visual world', 'start': 840.41, 'duration': 6.84} {'text': 'was simplified into simple geometric\nshapes and the goal is to be able to', 'start': 847.25, 'duration': 6.6} {'text': 'recognize them and reconstruct what\nthese shapes are. In 1966 there was a now', 'start': 853.85, 'duration': 9.569} {'text': 'famous MIT summer project called "The\nSummer Vision Project." The goal of this', 'start': 863.419, 'duration': 8.131} {'text': 'Summer Vision Project, I read: "is an\nattempt to use our summer workers', 'start': 871.55, 'duration': 6.89} {'text': 'effectively in a construction of a\nsignificant part of a visual system."', 'start': 878.44, 'duration': 5.8} {'text': "So the goal is in one summer we're gonna work\nout", 'start': 884.24, 'duration': 3.54} {'text': 'the bulk of the visual system. That was\nan ambitious goal. Fifty years have', 'start': 887.78, 'duration': 6.81} {'text': 'passed; the field of computer vision has\nblossomed from one summer project into a', 'start': 894.59, 'duration': 7.65} {'text': 'field of thousands of researchers\nworldwide still working on some of the', 'start': 902.24, 'duration': 5.37} {'text': 'most fundamental problems of vision. We\nstill have not yet solved vision but it', 'start': 907.61, 'duration': 6.33} {'text': 'has grown into one of the most important\nand fastest growing areas', 'start': 913.94, 'duration': 7.44} {'text': 'of artificial intelligence. Another\nperson that we should pay tribute to is', 'start': 921.38, 'duration': 6.03} {'text': 'David Marr. David Marr was a MIT vision\nscientist and he has written an', 'start': 927.41, 'duration': 7.14} {'text': 'influential book in the late 70s about\nwhat he thinks vision is and how we', 'start': 934.55, 'duration': 6.96} {'text': 'should go about computer vision\nand developing algorithms that can', 'start': 941.51, 'duration': 6.69} {'text': 'enable computers to recognize the visual\nworld. The thought process in his,', 'start': 948.2, 'duration': 8.82} {'text': 'in David Mars book is\nthat in order to take an image and', 'start': 957.02, 'duration': 5.42} {'text': 'arrive at a final holistic full 3d\nrepresentation of the visual world we', 'start': 962.44, 'duration': 8.199} {'text': 'have to go through several process. The\nfirst process is what he calls "primal sketch;"', 'start': 970.64, 'duration': 5.72} {'text': 'this is where mostly the edges,\nthe bars, the ends, the virtual lines, the', 'start': 976.36, 'duration': 6.7} {'text': 'curves, the boundaries, are represented\nand this is very much inspired by what', 'start': 983.06, 'duration': 5.91} {'text': 'neuroscientists have seen: Hubel and\nWiesel told us the early stage of visual', 'start': 988.97, 'duration': 5.669} {'text': 'processing has a lot to do with simple\nstructures like edges. Then the next step', 'start': 994.639, 'duration': 6.781} {'text': 'after the edges and the curves is what David Marr calls', 'start': 1001.42, 'duration': 4.44} {'text': '"two-and-a-half d sketch;" this is where we\nstart to piece together the surfaces,', 'start': 1005.86, 'duration': 6.44} {'text': 'the depth information, the layers, or the\ndiscontinuities of the visual scene,', 'start': 1012.3, 'duration': 6.54} {'text': 'and then eventually we put everything\ntogether and have a 3d model', 'start': 1018.85, 'duration': 6.08} {'text': 'hierarchically organized in terms of\nsurface and volumetric primitives and so on.', 'start': 1024.93, 'duration': 6.65} {'text': 'So that was a very idealized thought\nprocess of what vision is and this way', 'start': 1031.58, 'duration': 9.14} {'text': 'of thinking actually has dominated\ncomputer vision for several decades and', 'start': 1040.72, 'duration': 5.07} {'text': 'is also a very intuitive way for\nstudents to enter the field of vision', 'start': 1045.79, 'duration': 6.15} {'text': 'and think about how we can deconstruct\nthe visual information.', 'start': 1051.94, 'duration': 6.29} {'text': 'Another very important seminal group of\nwork happened in the 70s where people', 'start': 1059.31, 'duration': 9.07} {'text': 'began to ask the question "how can we\nmove beyond the simple block world and', 'start': 1068.38, 'duration': 6.78} {'text': 'start recognizing or representing real\nworld objects?" Think about the 70s,', 'start': 1075.16, 'duration': 7.349} {'text': "it's the time that there's very little\ndata available; computers are extremely", 'start': 1082.509, 'duration': 5.401} {'text': 'slow, PCs are not even around,\nbut computer scientists are starting to', 'start': 1087.91, 'duration': 5.45} {'text': 'think about how we can recognize and\nrepresent objects. So in Palo Alto', 'start': 1093.36, 'duration': 6.81} {'text': 'both at Stanford as well as SRI, two\ngroups of scientists that propose', 'start': 1100.17, 'duration': 6.479} {'text': 'similar ideas: one is called "generalized\ncylinder," one is called "pictorial structure."', 'start': 1106.649, 'duration': 6.091} {'text': 'The basic idea is that every\nobject is composed of simple geometric', 'start': 1112.74, 'duration': 7.32} {'text': 'primitives; for example a person can be\npieced together by generalized', 'start': 1120.06, 'duration': 5.45} {'text': 'cylindrical shapes or a person can be\npieced together by critical part in', 'start': 1125.51, 'duration': 5.829} {'text': 'their elastic distance between\nthese parts', 'start': 1131.339, 'duration': 4.74} {'text': 'so either representation is a way to\nreduce the complex structure of the', 'start': 1136.079, 'duration': 7.801} {'text': 'object into a collection of\nsimpler shapes and their geometric configuration.', 'start': 1143.88, 'duration': 7.26} {'text': 'These work have been\ninfluential for quite a few, quite a few years', 'start': 1151.14, 'duration': 8.08} {'text': 'and then in the 80s David Lowe, here\nis another example of thinking how to', 'start': 1159.22, 'duration': 8.41} {'text': 'reconstruct or recognize the visual\nworld from simple world structures, this', 'start': 1167.63, 'duration': 6.069} {'text': 'work is by David Lowe which he tries to\nrecognize razors by constructing', 'start': 1173.699, 'duration': 9.741} {'text': 'lines and edges and and mostly\nstraight lines and their combination.', 'start': 1183.44, 'duration': 7.42} {'text': 'So there was a lot of effort in trying to\nthink what what is the tasks in computer', 'start': 1190.86, 'duration': 10.28} {'text': 'vision in the 60s 70s and 80s and frankly\nit was very hard to solve the problem of', 'start': 1201.149, 'duration': 9.261} {'text': "object recognition; everything I've shown\nyou so far are very audacious ambitious", 'start': 1210.41, 'duration': 7.57} {'text': 'attempts but they remain at the level of\ntoy examples', 'start': 1217.98, 'duration': 6.18} {'text': 'or just a few examples. Not a lot of\nprogress have been made in terms of', 'start': 1224.16, 'duration': 6.659} {'text': 'delivering something that can work in\nreal world. So as people think about what', 'start': 1230.819, 'duration': 7.2} {'text': 'are the problems to solving vision one\nimportant question came around is:', 'start': 1238.019, 'duration': 5.69} {'text': 'if object recognition is too hard,\nmaybe we should first do object segmentation,', 'start': 1243.709, 'duration': 6.491} {'text': 'that is the task of taking\nan image and group the pixels into meaningful areas.', 'start': 1250.2, 'duration': 8.56} {'text': 'We might not know the\npixels that group together is called a person,', 'start': 1258.76, 'duration': 5.12} {'text': 'but we can extract out all the\npixels that belong to the person from its background;', 'start': 1263.88, 'duration': 6.26} {'text': "that is called image\nsegmentation. So here's one very early", 'start': 1270.14, 'duration': 5.199} {'text': 'seminal work by Jitendra Malik and his\nstudent Jianbo Shi from Berkeley from', 'start': 1275.339, 'duration': 6.42} {'text': 'using a graph theory algorithm for the\nproblem of image segmentation.', 'start': 1281.76, 'duration': 8.12} {'text': "Here's another problem that made some headway\nahead of many other problems in", 'start': 1289.88, 'duration': 9.72} {'text': 'computer vision, which is face detection.\nFaces one of the most important objects', 'start': 1299.61, 'duration': 6.24} {'text': 'to humans, probably the most important\nobjects to humans, around the time of', 'start': 1305.85, 'duration': 5.929} {'text': '1999 to 2000 machine learning techniques,\nespecially statistical machine', 'start': 1311.779, 'duration': 7.3} {'text': 'learning techniques start to gain\nmomentum. These are techniques such as', 'start': 1319.079, 'duration': 6.141} {'text': 'support vector machines, boosting,\ngraphical models, including the first', 'start': 1325.22, 'duration': 6.4} {'text': 'wave of neural networks. One particular\nwork that made a lot of contribution was', 'start': 1331.62, 'duration': 6.829} {'text': 'using AdaBoost algorithm to do\nreal-time face detection by Paul Viola', 'start': 1338.449, 'duration': 6.49} {'text': "and Michael Jones and there's a lot to\nadmire in this work. It was done in 2001", 'start': 1344.939, 'duration': 6.84} {'text': "when computer chips are still very very\nslow but they're able to do face", 'start': 1351.779, 'duration': 4.951} {'text': 'detection in\nimages in near-real-time and after the', 'start': 1356.73, 'duration': 5.82} {'text': 'publication of this paper in five years\ntime, 2006, Fujifilm rolled out the first', 'start': 1362.55, 'duration': 8.25} {'text': 'digital camera that has a real-time\nface detector in the in the camera so it', 'start': 1370.8, 'duration': 8.16} {'text': 'was a very rapid transfer from basic\nscience research to real world application.', 'start': 1378.96, 'duration': 7.0} {'text': 'So as a field we continue to\nexplore how we can do object recognition', 'start': 1385.96, 'duration': 7.96} {'text': 'better so one of the very influential\nway of thinking in the late 90s til the', 'start': 1393.93, 'duration': 8.79} {'text': 'first 10 years of 2000 is feature based\nobject recognition and here is a seminal', 'start': 1402.72, 'duration': 8.58} {'text': 'work by David Lowe called SIFT feature. \nThe idea is that to match and the entire object', 'start': 1411.3, 'duration': 8.37} {'text': 'for example here is a stop sign to\nanother stop sight is very difficult', 'start': 1419.67, 'duration': 5.19} {'text': 'because there might be all kinds of\nchanges due to camera angles, occlusion,', 'start': 1424.86, 'duration': 6.2} {'text': 'viewpoint, lighting, and just the\nintrinsic variation of the object itself', 'start': 1431.06, 'duration': 6.15} {'text': "but it's inspired to observe that there\nare some parts of the object,", 'start': 1437.21, 'duration': 7.47} {'text': 'some features, that tend to remain diagnostic\nand invariant to changes so the task of', 'start': 1444.68, 'duration': 10.32} {'text': 'object recognition began with identifying\nthese critical features on the object', 'start': 1455.01, 'duration': 6.6} {'text': "and then match the features to a similar\nobject, that's a easier task than pattern", 'start': 1461.61, 'duration': 6.959} {'text': 'matching the entire object. So here is a\nfigure from his paper where it shows', 'start': 1468.569, 'duration': 7.501} {'text': 'that a handful, several dozen SIFT\nfeatures from one stop sign are', 'start': 1476.07, 'duration': 5.99} {'text': 'identified and matched to the SIFT\nfeatures of another stop sign.', 'start': 1482.06, 'duration': 7.38} {'text': 'Using the same building block which is\nfeatures, diagnostic features in images,', 'start': 1491.13, 'duration': 8.2} {'text': 'we have as a field has made another step\nforward and start to recognizing', 'start': 1499.33, 'duration': 5.45} {'text': 'holistic scenes. Here is an example\nalgorithm called Spatial Pyramid Matching;', 'start': 1504.78, 'duration': 7.54} {'text': 'the idea is that there are\nfeatures in the images that can give us', 'start': 1512.32, 'duration': 6.3} {'text': "clues about which type of scene it is,\nwhether it's a landscape or a kitchen or", 'start': 1518.62, 'duration': 5.13} {'text': 'a highway and so on and this particular\nwork takes these features from different', 'start': 1523.75, 'duration': 7.83} {'text': 'parts of the image and in different\nresolutions and put them together in a', 'start': 1531.58, 'duration': 5.55} {'text': 'feature descriptor and then we do\nsupport vector machine algorithm on top of that.', 'start': 1537.13, 'duration': 7.65} {'text': 'Similarly a very similar work\nhas gained momentum in human recognition', 'start': 1544.78, 'duration': 9.15} {'text': 'so putting together these features well\nwe have a number of work that looks at', 'start': 1553.93, 'duration': 9.06} {'text': 'how we can compose human bodies in more\nrealistic images and recognize them.', 'start': 1562.99, 'duration': 7.5} {'text': 'So one work is called the "histogram of\ngradients," another work is called', 'start': 1570.49, 'duration': 5.22} {'text': '"deformable part models," so as you\ncan see as we move from the 60s 70s 80s', 'start': 1575.71, 'duration': 11.06} {'text': "towards the first decade of the 21st\ncentury one thing is changing and that's", 'start': 1586.77, 'duration': 7.39} {'text': 'the quality of the pictures were no\nlonger, with the Internet the the the', 'start': 1594.16, 'duration': 6.54} {'text': 'growth of the Internet the digital\ncameras were having better and better', 'start': 1600.7, 'duration': 4.98} {'text': 'data to study computer vision. So one of\nthe outcome in the early 2000s is that', 'start': 1605.68, 'duration': 8.7} {'text': 'the field of computer vision has defined\na very important building block problem to solve.', 'start': 1614.38, 'duration': 8.46} {'text': "It's not the only problem to solve but", 'start': 1622.84, 'duration': 2.76} {'text': 'in terms of recognition this is a very\nimportant problem to solve which is', 'start': 1625.6, 'duration': 5.52} {'text': 'object recognition. I talked about object\nrecognition all along but in the early', 'start': 1631.12, 'duration': 7.83} {'text': '2000s we began to have benchmark data\nset that can enable us to measure the', 'start': 1638.95, 'duration': 7.65} {'text': 'progress of object recognition. One of\nthe most influential benchmark data set', 'start': 1646.6, 'duration': 6.33} {'text': "is called PASCAL Visual Object Challenge,\nand it's a data set composed of 20", 'start': 1652.93, 'duration': 8.55} {'text': 'object classes, three of them are shown\nhere: train, airplane, person; I think it', 'start': 1661.48, 'duration': 7.02} {'text': 'also has cows, bottles, cats, and so on; and\nthe data set is composed of several', 'start': 1668.5, 'duration': 8.94} {'text': 'thousand to ten thousand images per\ncategory and then the field different', 'start': 1677.44, 'duration': 6.84} {'text': 'groups develop algorithm to test\nagainst the testing set and see how we', 'start': 1684.28, 'duration': 7.47} {'text': 'have made progress. So here is a figure\nthat shows from year 2007 to year 2012.', 'start': 1691.75, 'duration': 8.12} {'text': 'The performance on detecting objects the\n20 object in this image in a in a', 'start': 1699.87, 'duration': 11.23} {'text': 'benchmark data set has steadily\nincreased. So there was a lot of progress made.', 'start': 1711.1, 'duration': 7.58} {'text': 'Around that time a group of us from\nPrinceton to Stanford also began to ask', 'start': 1718.68, 'duration': 6.49} {'text': 'a harder question to ourselves as well\nas our field which is: are we ready', 'start': 1725.17, 'duration': 8.16} {'text': "to recognize every object or most of the\nobject in the world. It's also motivated", 'start': 1733.33, 'duration': 6.93} {'text': 'by an observation that is rooted in\nmachine learning which is that most of', 'start': 1740.26, 'duration': 7.71} {'text': "the machine learning algorithms it\ndoesn't matter if it's graphical model,", 'start': 1747.97, 'duration': 4.44} {'text': 'or support vector machine, or AdaBoost,\nis very likely to overfit in', 'start': 1752.41, 'duration': 7.66} {'text': 'the training process and part of the\nproblem is visual data is very complex', 'start': 1760.07, 'duration': 5.34} {'text': "because it's complex our models tend to\nhave a high dimension a high dimension", 'start': 1765.41, 'duration': 7.29} {'text': "of input and have to have a lot of\nparameters to fit and when we don't have", 'start': 1772.7, 'duration': 4.859} {'text': 'enough training data overfitting happens\nvery fast and then we cannot generalize', 'start': 1777.559, 'duration': 6.601} {'text': 'very well. So motivated by this dual\nreason, one is just want to recognize the', 'start': 1784.16, 'duration': 8.28} {'text': 'world of all the objects, the other\none is to come back the machine learning', 'start': 1792.44, 'duration': 5.9} {'text': 'overcome the the machine learning\nbottleneck of overfitting, we began this', 'start': 1798.34, 'duration': 6.28} {'text': 'project called ImageNet. We wanted to\nput together the largest possible dataset', 'start': 1804.62, 'duration': 6.52} {'text': 'of all the pictures we can find, the\nworld of objects, and use that for', 'start': 1811.14, 'duration': 6.76} {'text': 'training as well as for benchmarking. So\nit was a project that took us about', 'start': 1817.91, 'duration': 5.34} {'text': 'three years, lots of hard work; it\nbasically began with downloading', 'start': 1823.25, 'duration': 7.08} {'text': 'billions of images from the internet\norganized by the dictionary we called', 'start': 1830.33, 'duration': 7.29} {'text': 'WordNet which is tens of thousands of\nobject classes and then we have to use', 'start': 1837.62, 'duration': 8.15} {'text': 'some clever crowd engineering trick a\nmethod using Amazon Mechanical Turk', 'start': 1845.77, 'duration': 6.46} {'text': 'platform to sort, clean, label each of the\nimages. The end result is a ImageNet of', 'start': 1852.23, 'duration': 10.04} {'text': 'almost 15 million or 40 million plus\nimages organized in twenty-two thousand', 'start': 1862.27, 'duration': 8.56} {'text': 'categories of objects and scenes and\nthis is the gigantic, probably the', 'start': 1870.83, 'duration': 10.05} {'text': 'biggest dataset produced in the field of\nAI at that time and it began to push', 'start': 1880.88, 'duration': 8.409} {'text': 'forward the algorithm development of\nobject recognition into another phase.', 'start': 1889.289, 'duration': 6.47} {'text': 'Especially important is how to benchmark\nthe progress', 'start': 1895.759, 'duration': 5.441} {'text': 'so starting 2009 the ImageNet team rolled\nout an international challenge called', 'start': 1901.2, 'duration': 8.219} {'text': 'ImageNet Large-Scale Visual Recognition\nChallenge and for this challenge we put', 'start': 1909.419, 'duration': 7.89} {'text': 'together a more stringent test set of\n1.4 million objects across 1,000 object', 'start': 1917.309, 'duration': 8.881} {'text': 'classes and this is to test the image\nclassification recognition results for', 'start': 1926.19, 'duration': 7.439} {'text': "the computer vision algorithms. So here's\nthe example picture and if an algorithm", 'start': 1933.629, 'duration': 8.36} {'text': 'can output 5 labels and and top five\nlabels includes the correct object in', 'start': 1941.989, 'duration': 10.27} {'text': 'this picture then we call this a success.\nSo here is a result summary of the', 'start': 1952.259, 'duration': 10.65} {'text': 'ImageNet Challenge, of the image\nclassification result from 2010', 'start': 1962.909, 'duration': 6.811} {'text': 'to 2015 so on x axis you see the\nyears and the y axis you see the error rate.', 'start': 1969.72, 'duration': 11.02} {'text': 'So the good news is the error rate\nis steadily decreasing to the point by', 'start': 1980.74, 'duration': 6.08} {'text': '2012 the error rate is so low is on par\nwith what humans can do and here a human', 'start': 1986.82, 'duration': 8.549} {'text': 'I mean a single Stanford PhD student who\nspend weeks doing this task as if', 'start': 1995.369, 'duration': 9.99} {'text': "he were a computer participating in the\nImageNet Challenge. So that's a lot of", 'start': 2005.359, 'duration': 7.111} {'text': 'progress made even though we have not\nsolved all the problems of object', 'start': 2012.47, 'duration': 7.199} {'text': "recognition which you'll learn about in\nthis class", 'start': 2019.669, 'duration': 3.441} {'text': "but to go from an error rate that's\nunacceptable for real-world application", 'start': 2023.11, 'duration': 7.38} {'text': 'all the way to on par being on par with\nhumans in ImageNet challenge, the field', 'start': 2030.49, 'duration': 5.91} {'text': 'took only a few years. And one particular\nmoment you should notice on this graph', 'start': 2036.4, 'duration': 9.24} {'text': 'is the the year 2012. In the first two\nyears our error rate hovered around 25', 'start': 2045.64, 'duration': 10.08} {'text': 'percent but in 2012 the error rate was\ndropped more almost 10 percent to 16', 'start': 2055.72, 'duration': 9.93} {'text': "percent even though now it's better but\nthat drop was very significant and the", 'start': 2065.65, 'duration': 7.32} {'text': 'winning algorithm of that year is a\nconvolutional neural network model that', 'start': 2072.97, 'duration': 9.6} {'text': 'beat all other algorithms around that\ntime to win the ImageNet challenge and', 'start': 2082.57, 'duration': 7.28} {'text': 'this is the focus of our whole course\nthis quarter is to look at to have a', 'start': 2089.85, 'duration': 8.35} {'text': 'deep dive into what convolutional neural\nnetwork models are and another name for', 'start': 2098.2, 'duration': 7.5} {'text': 'this is deep learning by by popular', 'start': 2105.7, 'duration': 4.67} {'text': "popular name now it's called deep\nlearning and to look at what these", 'start': 2110.52, 'duration': 4.81} {'text': 'models are what are the principles what\nare the good practices what are the', 'start': 2115.33, 'duration': 5.099} {'text': 'recent progress of this model, but\nhere is where the history was made is', 'start': 2120.429, 'duration': 5.971} {'text': 'that we, around 2012 convolutional\nneural network model or deep learning', 'start': 2126.4, 'duration': 6.6} {'text': 'models showed the tremendous capacity\nand ability in making a good progress in', 'start': 2133.0, 'duration': 8.309} {'text': 'the field of computer vision along with\nseveral other sister fields like natural', 'start': 2141.309, 'duration': 6.061} {'text': "language processing and speech\nrecognition. So without further ado I'm", 'start': 2147.37, 'duration': 4.53} {'text': 'going to hand the rest of the lecture to\nto Justin to talk about the overview of', 'start': 2151.9, 'duration': 8.73} {'text': 'CS 231n. ', 'start': 2160.63, 'duration': 1.87} {'text': 'Alright, thanks so much Fei-Fei.', 'start': 2163.0, 'duration': 1.763} {'text': "I'll take it over from here.", 'start': 2165.0, 'duration': 3.158} {'text': 'So now I want to shift gears a little bit', 'start': 2168.189, 'duration': 1.721} {'text': 'and talk a little bit more\nabout this class CS231n.', 'start': 2169.91, 'duration': 4.167} {'text': 'So this class focuses\non one of these most,', 'start': 2175.436, 'duration': 3.2} {'text': 'so the primary focus of this class', 'start': 2178.636, 'duration': 2.178} {'text': 'is this image classification problem', 'start': 2180.814, 'duration': 2.136} {'text': 'which we previewed a\nlittle bit in the contex', 'start': 2182.95, 'duration': 2.319} {'text': 'of the ImageNet Challenge.', 'start': 2185.269, 'duration': 1.768} {'text': 'So in image classification, again,', 'start': 2187.037, 'duration': 1.811} {'text': 'the setup is that your\nalgorithm looks at an image', 'start': 2188.848, 'duration': 2.622} {'text': 'and then picks from among\nsome fixed set of categories', 'start': 2191.47, 'duration': 2.578} {'text': 'to classify that image.', 'start': 2194.048, 'duration': 2.395} {'text': 'And, this might seem like\nsomewhat of a restrictive', 'start': 2196.443, 'duration': 3.107} {'text': "or artificial setup, but\nit's actual quite general.", 'start': 2199.55, 'duration': 2.956} {'text': 'And, this problem can be applied\nin many different settings', 'start': 2202.506, 'duration': 3.015} {'text': 'both in industry and academia\nand many different places.', 'start': 2205.521, 'duration': 4.109} {'text': 'So for example, you could\napply this to recognizing food', 'start': 2209.63, 'duration': 3.327} {'text': 'or recognizing calories\nin food or recognizing', 'start': 2212.957, 'duration': 1.949} {'text': 'different artworks, different\nproduct out in the world.', 'start': 2214.906, 'duration': 3.137} {'text': 'So this relatively basic\ntool of image classification', 'start': 2218.043, 'duration': 3.533} {'text': 'is super useful on its\nown and could be applied', 'start': 2221.576, 'duration': 2.696} {'text': 'all over the place for many\ndifferent applications.', 'start': 2224.272, 'duration': 4.231} {'text': "But, in this course,\nwe're also going to talk", 'start': 2228.503, 'duration': 2.182} {'text': 'about several other visual\nrecognition problems', 'start': 2230.685, 'duration': 3.121} {'text': 'that build upon many of\nthe tools that we develop', 'start': 2233.806, 'duration': 2.867} {'text': 'for the purpose of image classification.', 'start': 2236.673, 'duration': 2.987} {'text': "We'll talk about other problems", 'start': 2239.66, 'duration': 1.606} {'text': 'such as object detection\nor image captioning.', 'start': 2241.266, 'duration': 3.517} {'text': 'So the setup in object detection', 'start': 2244.783, 'duration': 1.882} {'text': 'is a little bit different.', 'start': 2246.665, 'duration': 1.77} {'text': 'Rather than classifying an entire image', 'start': 2248.435, 'duration': 2.274} {'text': 'as a cat or a dog or a horse or whatnot,', 'start': 2250.709, 'duration': 3.018} {'text': 'instead we want to go in\nand draw bounding boxes', 'start': 2253.727, 'duration': 2.124} {'text': 'and say that there is a\ndog here, and a cat here,', 'start': 2255.851, 'duration': 2.61} {'text': 'and a car over in the background,', 'start': 2258.461, 'duration': 1.89} {'text': 'and draw these boxes describing', 'start': 2260.351, 'duration': 1.835} {'text': 'where objects are in the image.', 'start': 2262.186, 'duration': 1.924} {'text': "We'll also talk about image captioning", 'start': 2264.11, 'duration': 2.212} {'text': 'where given an image the system', 'start': 2266.322, 'duration': 1.423} {'text': 'now needs to produce a\nnatural language sentence', 'start': 2267.745, 'duration': 2.366} {'text': 'describing the image.', 'start': 2270.111, 'duration': 1.364} {'text': 'It sounds like a really hard, complicated,', 'start': 2271.475, 'duration': 2.216} {'text': "and different problem, but we'll see", 'start': 2273.691, 'duration': 1.908} {'text': 'that many of the tools that we develop', 'start': 2275.599, 'duration': 1.62} {'text': 'in service of image classification', 'start': 2277.219, 'duration': 1.744} {'text': 'will be reused in these\nother problems as well.', 'start': 2278.963, 'duration': 3.917} {'text': 'So we mentioned this before in the context', 'start': 2286.482, 'duration': 1.969} {'text': 'of the ImageNet Challenge,\nbut one of the things', 'start': 2288.451, 'duration': 2.794} {'text': "that's really driven the\nprogress of the field", 'start': 2291.245, 'duration': 1.721} {'text': 'in recent years has been this adoption', 'start': 2292.966, 'duration': 1.432} {'text': 'of convolutional neural networks or CNNs', 'start': 2294.398, 'duration': 3.535} {'text': 'or sometimes called convnets.', 'start': 2297.933, 'duration': 2.417} {'text': 'So if we look at the\nalgorithms that have won', 'start': 2300.35, 'duration': 3.658} {'text': 'the ImageNet Challenge for\nthe last several years,', 'start': 2304.008, 'duration': 2.819} {'text': 'in 2011 we see this method from Lin et al', 'start': 2306.827, 'duration': 3.652} {'text': 'which is still hierarchical.', 'start': 2310.479, 'duration': 2.152} {'text': 'It consists of multiple layers.', 'start': 2312.631, 'duration': 2.229} {'text': 'So first we compute some features,', 'start': 2314.86, 'duration': 1.909} {'text': 'next we compute some local invariances,', 'start': 2316.769, 'duration': 1.973} {'text': 'some pooling, and go\nthrough several layers', 'start': 2318.742, 'duration': 2.469} {'text': 'of processing, and then finally feed', 'start': 2321.211, 'duration': 1.728} {'text': 'this resulting descriptor to a linear SVN.', 'start': 2322.939, 'duration': 3.337} {'text': "What you'll notice here is that\nthis is still hierarchical.", 'start': 2326.276, 'duration': 2.954} {'text': "We're still detecting edges.", 'start': 2329.23, 'duration': 1.323} {'text': "We're still having notions of invariance.", 'start': 2330.553, 'duration': 2.03} {'text': 'And, many of these\nintuitions will carry over', 'start': 2332.583, 'duration': 1.828} {'text': 'into convnets.', 'start': 2334.411, 'duration': 1.766} {'text': 'But, the breakthrough\nmoment was really in 2012', 'start': 2336.177, 'duration': 2.938} {'text': "when Jeff Hinton's group in Toronto", 'start': 2339.115, 'duration': 2.917} {'text': 'together with Alex\nKrizhevsky and Ilya Sutskever', 'start': 2343.693, 'duration': 3.373} {'text': 'who were his PHD student at that time', 'start': 2347.066, 'duration': 2.159} {'text': 'created this seven layer\nconvolutional neural network', 'start': 2349.225, 'duration': 3.279} {'text': 'now known as AlexNet,\nthen called Supervision', 'start': 2352.504, 'duration': 2.708} {'text': 'which just did very, very well\nin the ImageNet competition', 'start': 2355.212, 'duration': 2.957} {'text': 'in 2012.', 'start': 2358.169, 'duration': 1.482} {'text': 'And, since then every year\nthe winner of ImageNet', 'start': 2359.651, 'duration': 2.833} {'text': 'has been a neural network.', 'start': 2362.484, 'duration': 1.713} {'text': 'And, the trend has been\nthat these networks', 'start': 2364.197, 'duration': 1.714} {'text': 'are getting deeper and deeper each year.', 'start': 2365.911, 'duration': 2.185} {'text': 'So AlexNet was a seven or\neight layer neural network', 'start': 2368.096, 'duration': 3.465} {'text': 'depending on how exactly you count things.', 'start': 2371.561, 'duration': 2.031} {'text': 'In 2015 we had these much deeper networks.', 'start': 2373.592, 'duration': 1.969} {'text': 'GoogleNet from Google\nand VGG, the VGG network', 'start': 2375.561, 'duration': 3.957} {'text': 'from Oxford which was about\n19 layers at that time.', 'start': 2379.518, 'duration': 3.654} {'text': 'And, then in 2015 it got really crazy', 'start': 2383.172, 'duration': 1.799} {'text': 'and this paper came out\nfrom Microsoft Research Asia', 'start': 2384.971, 'duration': 3.627} {'text': 'called Residual Networks which\nwere 152 layers at that time.', 'start': 2388.598, 'duration': 3.775} {'text': 'And, since then it turns out you can get', 'start': 2392.373, 'duration': 2.664} {'text': 'a little bit better if you go up to 200,', 'start': 2395.037, 'duration': 1.708} {'text': 'but you run our of memory on your GPUs.', 'start': 2396.745, 'duration': 1.76} {'text': "We'll get into all of that later,", 'start': 2398.505, 'duration': 1.847} {'text': 'but the main takeaway here\nis that convolutional neural', 'start': 2400.352, 'duration': 2.744} {'text': 'networks really had\nthis breakthrough moment', 'start': 2403.096, 'duration': 1.728} {'text': "in 2012, and since then there's been", 'start': 2404.824, 'duration': 2.001} {'text': 'a lot of effort focused\nin tuning and tweaking', 'start': 2406.825, 'duration': 1.958} {'text': 'these algorithms to make them\nperform better and better', 'start': 2408.783, 'duration': 2.557} {'text': 'on this problem of image classification.', 'start': 2411.34, 'duration': 2.139} {'text': 'And, throughout the rest of the quarter,', 'start': 2413.479, 'duration': 2.0} {'text': "we're going to really dive in deep,", 'start': 2415.479, 'duration': 1.621} {'text': "and you'll understand exactly\nhow these different models", 'start': 2417.1, 'duration': 2.016} {'text': 'work.', 'start': 2419.116, 'duration': 0.833} {'text': "But, one point that's really important,", 'start': 2422.514, 'duration': 2.151} {'text': "it's true that the breakthrough moment", 'start': 2424.665, 'duration': 2.683} {'text': 'for convolutional neural\nnetworks was in 2012', 'start': 2427.348, 'duration': 2.912} {'text': 'when these networks performed very well', 'start': 2430.26, 'duration': 2.134} {'text': "on the ImageNet Challenge,\nbut they certainly weren't", 'start': 2432.394, 'duration': 2.428} {'text': 'invented in 2012.', 'start': 2434.822, 'duration': 1.729} {'text': 'These algorithms had actually been around', 'start': 2436.551, 'duration': 1.635} {'text': 'for quite a long time before that.', 'start': 2438.186, 'duration': 2.124} {'text': 'So one of the sort of foundational works', 'start': 2440.31, 'duration': 3.486} {'text': 'in this area of\nconvolutional neural networks', 'start': 2443.796, 'duration': 2.361} {'text': "was actually in the '90s from\nJan LeCun and collaborators", 'start': 2446.157, 'duration': 4.293} {'text': 'who at that time were at Bell Labs.', 'start': 2450.45, 'duration': 3.183} {'text': 'So in 1998 they build this\nconvolutional neural network', 'start': 2453.633, 'duration': 3.699} {'text': 'for recognizing digits.', 'start': 2457.332, 'duration': 1.497} {'text': 'They wanted to deploy\nthis and wanted to be able', 'start': 2458.829, 'duration': 3.762} {'text': 'to automatically recognize\nhandwritten checks', 'start': 2462.591, 'duration': 2.077} {'text': 'or addresses for the post office.', 'start': 2464.668, 'duration': 2.698} {'text': 'And, they built this\nconvolutional neural network', 'start': 2467.366, 'duration': 2.018} {'text': 'which could take in the pixels of an image', 'start': 2469.384, 'duration': 2.274} {'text': 'and then classify either what digit it was', 'start': 2471.658, 'duration': 2.924} {'text': 'or what letter it was or whatnot.', 'start': 2474.582, 'duration': 2.655} {'text': 'And, the structure of this network', 'start': 2477.237, 'duration': 1.969} {'text': 'actually look pretty\nsimilar to the AlexNet', 'start': 2479.206, 'duration': 2.0} {'text': 'architecture that was used in 2012.', 'start': 2481.206, 'duration': 2.412} {'text': "Here we see that, you know, we're taking", 'start': 2483.618, 'duration': 1.831} {'text': 'in these raw pixels.', 'start': 2485.449, 'duration': 1.229} {'text': 'We have many layers of\nconvolution and sub-sampling,', 'start': 2486.678, 'duration': 2.402} {'text': 'together with the so called\nfully connected layers.', 'start': 2489.08, 'duration': 2.318} {'text': 'All of which will be\nexplained in much more detail', 'start': 2491.398, 'duration': 1.997} {'text': 'later in the course.', 'start': 2493.395, 'duration': 1.319} {'text': 'But, if you just kind of\nlook at these two pictures,', 'start': 2494.714, 'duration': 2.002} {'text': 'they look pretty similar.', 'start': 2496.716, 'duration': 1.681} {'text': 'And, this architecture in 2012 has a lot', 'start': 2498.397, 'duration': 3.333} {'text': 'of these architectural similarities', 'start': 2502.609, 'duration': 1.84} {'text': "that are shared with this\nnetwork going back to the '90s.", 'start': 2504.449, 'duration': 4.85} {'text': 'So then the question you might ask', 'start': 2509.299, 'duration': 1.517} {'text': "is if these algorithms\nwere around since the '90s,", 'start': 2510.816, 'duration': 2.561} {'text': 'why have they only suddenly become popular', 'start': 2513.377, 'duration': 2.438} {'text': 'in the last couple of years?', 'start': 2515.815, 'duration': 1.639} {'text': "And, there's a couple\nreally key innovations", 'start': 2517.454, 'duration': 1.849} {'text': "that happened that have\nchanged since the '90s.", 'start': 2519.303, 'duration': 3.974} {'text': 'One is computation.', 'start': 2523.277, 'duration': 2.074} {'text': "Thanks to Moore's law, we've gotten", 'start': 2525.351, 'duration': 1.67} {'text': 'faster and faster computers every year.', 'start': 2527.021, 'duration': 2.196} {'text': 'And, this is kind of a coarse measure,', 'start': 2529.217, 'duration': 2.016} {'text': 'but if you just look at\nthe number of transistors', 'start': 2531.233, 'duration': 2.001} {'text': 'that are on chips, then that has grown', 'start': 2533.234, 'duration': 1.895} {'text': "by several orders of magnitude\nbetween the '90s and today.", 'start': 2535.129, 'duration': 3.445} {'text': "We've also had this advent\nof graphics processing units", 'start': 2538.574, 'duration': 4.469} {'text': 'or GPUs which are super parallelizable', 'start': 2543.043, 'duration': 2.835} {'text': 'and ended up being a perfect tool', 'start': 2545.878, 'duration': 2.227} {'text': 'for really crunching these\ncomputationally intensive', 'start': 2548.105, 'duration': 2.761} {'text': 'convolutional neural network models.', 'start': 2550.866, 'duration': 2.166} {'text': 'So just by having more compute available,', 'start': 2553.032, 'duration': 2.909} {'text': 'it allowed researchers to\nexplore with larger architectures', 'start': 2555.941, 'duration': 3.783} {'text': 'and larger models, and in some cases,', 'start': 2559.724, 'duration': 2.426} {'text': 'just increasing the model\nsize, but still using', 'start': 2562.15, 'duration': 1.976} {'text': 'these kind of classical approaches\nand classical algorithms', 'start': 2564.126, 'duration': 2.712} {'text': 'tends to work quite well.', 'start': 2566.838, 'duration': 1.638} {'text': 'So this idea of increasing computation', 'start': 2568.476, 'duration': 2.939} {'text': 'is super important in the\nhistory of deep learning.', 'start': 2571.415, 'duration': 4.139} {'text': 'I think the second key\ninnovation that changed', 'start': 2575.554, 'duration': 3.093} {'text': "between now and the '90s was data.", 'start': 2578.647, 'duration': 1.912} {'text': 'So these algorithms are\nvery hungry for data.', 'start': 2580.559, 'duration': 3.699} {'text': 'You need to feed them\na lot of labeled images', 'start': 2584.258, 'duration': 2.061} {'text': 'and labeled pixels for them\nto eventually work quite well.', 'start': 2586.319, 'duration': 3.076} {'text': "And, in the '90s there just wasn't", 'start': 2589.395, 'duration': 2.258} {'text': 'that much labeled data available.', 'start': 2591.653, 'duration': 2.488} {'text': 'This was, again, before\ntools like Mechanical Turk,', 'start': 2594.141, 'duration': 3.348} {'text': 'before the internet was\nsuper, super widely used.', 'start': 2597.489, 'duration': 2.743} {'text': 'And, it was very difficult to collect', 'start': 2600.232, 'duration': 1.639} {'text': 'large, varied datasets.', 'start': 2601.871, 'duration': 1.743} {'text': 'But, now in the 2010s\nwith datasets like PASCAL', 'start': 2603.614, 'duration': 3.917} {'text': 'and ImageNet, there existed\nthese relatively large,', 'start': 2608.583, 'duration': 3.05} {'text': 'high quality labeled\ndatasets that were, again,', 'start': 2611.633, 'duration': 2.595} {'text': 'orders and orders magnitude bigger', 'start': 2614.228, 'duration': 2.362} {'text': "than the dataset available in the '90s.", 'start': 2616.59, 'duration': 2.185} {'text': 'And, these much large datasets, again,', 'start': 2618.775, 'duration': 1.847} {'text': 'allowed us to work with\nhigher capacity models', 'start': 2620.622, 'duration': 2.531} {'text': 'and train these models to\nactually work quite well', 'start': 2623.153, 'duration': 2.108} {'text': 'on real world problems.', 'start': 2625.261, 'duration': 1.896} {'text': 'But, the critical takeaway here is', 'start': 2627.157, 'duration': 2.105} {'text': 'that convolutional neural networks', 'start': 2629.262, 'duration': 1.761} {'text': 'although they seem like this\nsort of fancy, new thing', 'start': 2631.023, 'duration': 3.136} {'text': "that's only popped up in\nthe last couple of years,", 'start': 2634.159, 'duration': 1.958} {'text': "that's really not the case.", 'start': 2636.117, 'duration': 1.41} {'text': 'And, these class of\nalgorithms have existed', 'start': 2637.527, 'duration': 2.056} {'text': 'for quite a long time in\ntheir own right as well.', 'start': 2639.583, 'duration': 4.083} {'text': "Another thing I'd like to point out", 'start': 2645.015, 'duration': 2.9} {'text': "in computer vision we're in the business", 'start': 2647.915, 'duration': 1.809} {'text': 'of trying to build machines\nthat can see like people.', 'start': 2649.724, 'duration': 3.031} {'text': 'And, people can actually\ndo a lot of amazing things', 'start': 2652.755, 'duration': 2.502} {'text': 'with their visual systems.', 'start': 2655.257, 'duration': 1.393} {'text': 'When you go around the world,', 'start': 2656.65, 'duration': 1.848} {'text': 'you do a lot more than just drawing boxes', 'start': 2658.498, 'duration': 2.536} {'text': 'around the objects and classifying\nthings as cats or dogs.', 'start': 2661.034, 'duration': 3.954} {'text': 'Your visual system is much\nmore powerful than that.', 'start': 2664.988, 'duration': 2.723} {'text': 'And, as we move forward in the field,', 'start': 2667.711, 'duration': 1.704} {'text': "I think there's still a\nton of open challenges", 'start': 2669.415, 'duration': 2.197} {'text': 'and open problems that we need to address.', 'start': 2671.612, 'duration': 2.435} {'text': 'And, we need to continue\nto develop our algorithms', 'start': 2674.047, 'duration': 2.583} {'text': 'to do even better and tackle\neven more ambitious problems.', 'start': 2676.63, 'duration': 3.59} {'text': 'Some examples of this are\ngoing back to these older ideas', 'start': 2680.22, 'duration': 2.744} {'text': 'in fact.', 'start': 2682.964, 'duration': 1.079} {'text': 'Things like semantic segmentation\nor perceptual grouping', 'start': 2684.043, 'duration': 2.88} {'text': 'where rather than\nlabeling the entire image,', 'start': 2686.923, 'duration': 2.369} {'text': 'we want to understand for\nevery pixel in the image', 'start': 2689.292, 'duration': 2.677} {'text': 'what is it doing, what does it mean.', 'start': 2691.969, 'duration': 1.897} {'text': "And, we'll revisit that\nidea a little bit later", 'start': 2693.866, 'duration': 1.795} {'text': 'in the course.', 'start': 2695.661, 'duration': 1.185} {'text': "There's definitely work going back", 'start': 2696.846, 'duration': 1.607} {'text': 'to this idea of 3D understanding,', 'start': 2698.453, 'duration': 1.681} {'text': 'of reconstructing the entire world,', 'start': 2700.134, 'duration': 2.243} {'text': "and that's still an\nunsolved problem I think.", 'start': 2702.377, 'duration': 3.75} {'text': "There're just tons and tons of other tasks", 'start': 2707.498, 'duration': 1.512} {'text': 'that you can imagine.', 'start': 2709.01, 'duration': 1.168} {'text': 'For example activity recognition,', 'start': 2710.178, 'duration': 1.639} {'text': "if I'm given a video of some person", 'start': 2711.817, 'duration': 1.621} {'text': "doing some activity, what's the best way", 'start': 2713.438, 'duration': 1.774} {'text': 'to recognize that activity?', 'start': 2715.212, 'duration': 1.513} {'text': "That's quite a challenging\nproblem as well.", 'start': 2716.725, 'duration': 2.744} {'text': 'And, then as we move forward with things', 'start': 2719.469, 'duration': 1.817} {'text': 'like augmented reality\nand virtual reality,', 'start': 2721.286, 'duration': 1.988} {'text': 'and as new technologies\nand new types of sensors', 'start': 2723.274, 'duration': 2.058} {'text': "become available, I think we'll come up", 'start': 2725.332, 'duration': 2.246} {'text': 'with a lot of new, interesting\nhard and challenging', 'start': 2727.578, 'duration': 2.377} {'text': 'problems to tackle as a field.', 'start': 2729.955, 'duration': 2.5} {'text': 'So this is an example\nfrom some of my own work', 'start': 2733.916, 'duration': 4.008} {'text': 'in the vision lab on this\ndataset called Visual Genome.', 'start': 2737.924, 'duration': 4.304} {'text': "So here the idea is that\nwe're trying to capture", 'start': 2742.228, 'duration': 3.198} {'text': 'some of these intricacies\nin the real world.', 'start': 2745.426, 'duration': 2.048} {'text': 'Rather than maybe describing just boxes,', 'start': 2747.474, 'duration': 2.319} {'text': 'maybe we should be describing images', 'start': 2749.793, 'duration': 2.515} {'text': 'as these whole large graphs\nof semantically related', 'start': 2752.308, 'duration': 2.748} {'text': 'concepts that encompass\nnot just object identities', 'start': 2755.056, 'duration': 2.469} {'text': 'but also object relationships,\nobject attributes,', 'start': 2757.525, 'duration': 2.926} {'text': 'actions that are occurring in the scene,', 'start': 2760.451, 'duration': 2.139} {'text': 'and this type of\nrepresentation might allow us', 'start': 2762.59, 'duration': 4.381} {'text': 'to capture some of this\nrichness of the visual world', 'start': 2766.971, 'duration': 2.556} {'text': "that's left on the table when we're using", 'start': 2769.527, 'duration': 1.698} {'text': 'simple classification.', 'start': 2771.225, 'duration': 1.664} {'text': 'This is by no means a standard\napproach at this point,', 'start': 2772.889, 'duration': 2.381} {'text': 'but just kind of giving you this sense', 'start': 2775.27, 'duration': 2.06} {'text': "that there's so much more\nthat your visual system can do", 'start': 2777.33, 'duration': 2.305} {'text': 'that is maybe not captured in this vanilla', 'start': 2779.635, 'duration': 2.955} {'text': 'image classification setup.', 'start': 2782.59, 'duration': 2.25} {'text': 'I think another really interesting work', 'start': 2788.003, 'duration': 1.741} {'text': 'that kind of points in this direction', 'start': 2789.744, 'duration': 1.848} {'text': "actually comes from\nFei-Fei's grad school days", 'start': 2791.592, 'duration': 2.553} {'text': 'when she was doing her PHD at Cal Tech', 'start': 2794.145, 'duration': 2.698} {'text': 'with her advisors there.', 'start': 2796.843, 'duration': 2.109} {'text': 'In this setup, they had\npeople, they stuck people,', 'start': 2798.952, 'duration': 2.74} {'text': 'and they showed people this\nimage for just half a second.', 'start': 2801.692, 'duration': 2.912} {'text': 'So they flashed this\nimage in front of them', 'start': 2804.604, 'duration': 1.698} {'text': 'for just a very short period of time,', 'start': 2806.302, 'duration': 1.594} {'text': 'and even in this very, very rapid exposure', 'start': 2807.896, 'duration': 2.273} {'text': 'to an image, people were able to write', 'start': 2810.169, 'duration': 1.939} {'text': 'these long descriptive paragraphs', 'start': 2812.108, 'duration': 1.925} {'text': 'giving a whole story of the image.', 'start': 2814.033, 'duration': 2.44} {'text': 'And, this is quite remarkable\nif you think about it', 'start': 2816.473, 'duration': 3.811} {'text': 'that after just half a second\nof looking at this image,', 'start': 2820.284, 'duration': 3.408} {'text': 'a person was able to say that this is', 'start': 2823.692, 'duration': 1.868} {'text': 'some kind of a game or\nfight, two groups of men.', 'start': 2825.56, 'duration': 2.921} {'text': 'The man on the left is throwing something.', 'start': 2828.481, 'duration': 1.894} {'text': 'Outdoors because it seem like\nI have an impression of grass,', 'start': 2830.375, 'duration': 2.759} {'text': 'and so on and so on.', 'start': 2833.134, 'duration': 1.442} {'text': 'And, you can imagine that if a person', 'start': 2834.576, 'duration': 1.44} {'text': 'were to look even longer at this image,', 'start': 2836.016, 'duration': 1.601} {'text': 'they could write probably a whole novel', 'start': 2837.617, 'duration': 1.552} {'text': 'about who these people\nare, and why are they', 'start': 2839.169, 'duration': 1.773} {'text': 'in this field playing this game.', 'start': 2840.942, 'duration': 1.365} {'text': 'They could go on and on and on', 'start': 2842.307, 'duration': 1.378} {'text': 'roping in things from\ntheir external knowledge', 'start': 2843.685, 'duration': 1.928} {'text': 'and their prior experience.', 'start': 2845.613, 'duration': 1.574} {'text': 'This is in some sense the\nholy grail of computer vision.', 'start': 2847.187, 'duration': 3.11} {'text': 'To sort of understand\nthe story of an image', 'start': 2850.297, 'duration': 2.362} {'text': 'in a very rich and deep way.', 'start': 2852.659, 'duration': 2.004} {'text': 'And, I think that despite\nthe massive progress', 'start': 2854.663, 'duration': 2.269} {'text': "in the field that we've had\nover the past several years,", 'start': 2856.932, 'duration': 2.774} {'text': "we're still quite a long way\nfrom achieving this holy grail.", 'start': 2859.706, 'duration': 4.754} {'text': 'Another image that I\nthink really exemplifies', 'start': 2864.46, 'duration': 2.103} {'text': "this idea actually comes, again,\nfrom Andrej Karpathy's blog", 'start': 2866.563, 'duration': 3.909} {'text': 'is this amazing image.', 'start': 2870.472, 'duration': 2.418} {'text': 'Many of you smiled, many of you laughed.', 'start': 2872.89, 'duration': 1.501} {'text': 'I think this is a pretty funny image.', 'start': 2874.391, 'duration': 1.821} {'text': 'But, why is it a funny image?', 'start': 2876.212, 'duration': 1.484} {'text': "Well we've got a man standing on a scale,", 'start': 2877.696, 'duration': 2.199} {'text': 'and we know that people\nare kind of self conscious', 'start': 2879.895, 'duration': 1.712} {'text': 'about their weight sometimes,\nand scales measure weight.', 'start': 2881.607, 'duration': 2.773} {'text': "Then we've got this other guy behind him", 'start': 2884.38, 'duration': 2.519} {'text': 'pushing his foot down on the scale,', 'start': 2886.899, 'duration': 1.892} {'text': 'and we know that because\nof the way scales work', 'start': 2888.791, 'duration': 2.109} {'text': 'that will cause him to\nhave an inflated reading', 'start': 2890.9, 'duration': 2.058} {'text': 'on the scale.', 'start': 2892.958, 'duration': 0.909} {'text': "But, there's more.", 'start': 2893.867, 'duration': 1.028} {'text': 'We know that this person\nis not just any person.', 'start': 2894.895, 'duration': 1.924} {'text': 'This is actually Barack\nObama who was at the time', 'start': 2896.819, 'duration': 2.681} {'text': 'President of the United States,', 'start': 2899.5, 'duration': 1.405} {'text': 'and we know that Presidents\nof the United States', 'start': 2900.905, 'duration': 1.636} {'text': 'are supposed to be respectable\npoliticians that are', 'start': 2902.541, 'duration': 2.2} {'text': '[laughing]', 'start': 2904.741, 'duration': 2.304} {'text': 'probably not supposed to be playing jokes', 'start': 2907.045, 'duration': 2.109} {'text': 'on their compatriots in this way.', 'start': 2909.154, 'duration': 2.15} {'text': "We know that there's these people", 'start': 2911.304, 'duration': 1.409} {'text': 'in the background that\nare laughing and smiling,', 'start': 2912.713, 'duration': 1.851} {'text': "and we know that that means that they're", 'start': 2914.564, 'duration': 1.502} {'text': 'understanding something about the scene.', 'start': 2916.066, 'duration': 1.846} {'text': 'We have some understanding that they know', 'start': 2917.912, 'duration': 1.685} {'text': 'that President Obama\nis this respectable guy', 'start': 2919.597, 'duration': 1.978} {'text': "who's looking at this other guy.", 'start': 2921.575, 'duration': 1.291} {'text': 'Like, this is crazy.', 'start': 2922.866, 'duration': 0.901} {'text': "There's so much going on in this image.", 'start': 2923.767, 'duration': 2.063} {'text': 'And, our computer vision algorithms today', 'start': 2925.83, 'duration': 2.337} {'text': 'are actually a long way\nI think from this true,', 'start': 2928.167, 'duration': 2.941} {'text': 'deep understanding of images.', 'start': 2931.108, 'duration': 1.894} {'text': 'So I think that sort of\ndespite the massive progress', 'start': 2933.002, 'duration': 3.03} {'text': 'in the field, we really\nhave a long way to go.', 'start': 2936.032, 'duration': 2.745} {'text': "To me, that's really\nexciting as a researcher", 'start': 2938.777, 'duration': 2.608} {'text': "'cause I think that we'll have", 'start': 2941.385, 'duration': 1.245} {'text': 'just a lot of really\nexciting, cool problems', 'start': 2942.63, 'duration': 1.981} {'text': 'to tackle moving forward.', 'start': 2944.611, 'duration': 2.083} {'text': "So I hope at this point I've\ndone a relatively good job", 'start': 2947.913, 'duration': 2.289} {'text': 'to convince you that computer\nvision is really interesting.', 'start': 2950.202, 'duration': 2.852} {'text': "It's really exciting.", 'start': 2953.054, 'duration': 1.154} {'text': 'It can be very useful.', 'start': 2954.208, 'duration': 2.121} {'text': 'It can go out and make\nthe world a better place', 'start': 2956.329, 'duration': 1.986} {'text': 'in various ways.', 'start': 2958.315, 'duration': 1.728} {'text': 'Computer vision could be applied', 'start': 2960.043, 'duration': 1.548} {'text': 'in places like medical\ndiagnosis and self-driving cars', 'start': 2961.591, 'duration': 2.968} {'text': 'and robotics and all\nthese different places.', 'start': 2964.559, 'duration': 3.575} {'text': 'In addition to sort of tying\nback to sort of this core', 'start': 2968.134, 'duration': 2.579} {'text': 'idea of understanding human intelligence.', 'start': 2970.713, 'duration': 2.407} {'text': 'So to me, I think that computer vision', 'start': 2973.12, 'duration': 1.729} {'text': 'is this fantastically\namazing, interesting field,', 'start': 2974.849, 'duration': 2.292} {'text': "and I'm really glad that over the course", 'start': 2977.141, 'duration': 1.634} {'text': "of the quarter, we'll\nget to really dive in", 'start': 2978.775, 'duration': 1.7} {'text': 'and dig into all these different details', 'start': 2980.475, 'duration': 1.862} {'text': 'about how these algorithms\nare working these days.', 'start': 2982.337, 'duration': 3.897} {'text': "That's sort of my pitch\nabout computer vision", 'start': 2986.234, 'duration': 2.715} {'text': 'and about the history of computer vision.', 'start': 2988.949, 'duration': 1.724} {'text': "I don't know if there's\nany questions about this", 'start': 2990.673, 'duration': 1.61} {'text': 'at this time.', 'start': 2992.283, 'duration': 1.083} {'text': 'Okay.', 'start': 2995.707, 'duration': 1.348} {'text': 'So then I want to talk a little bit more', 'start': 2997.055, 'duration': 1.29} {'text': 'about the logistics of this class', 'start': 2998.345, 'duration': 2.063} {'text': 'for the rest of the quarter.', 'start': 3000.408, 'duration': 2.0} {'text': 'So you might ask who are we?', 'start': 3002.408, 'duration': 1.974} {'text': 'So this class is taught by Fei-Fei Li', 'start': 3004.382, 'duration': 2.522} {'text': 'who is a professor of computer\nscience here at Standford', 'start': 3006.904, 'duration': 4.367} {'text': "who's my advisor and director\nof the Stanford Vision Lab", 'start': 3011.271, 'duration': 3.245} {'text': 'and also the Stanford AI Lab.', 'start': 3014.516, 'duration': 2.336} {'text': 'The other two instructors\nare me, Justin Johnson,', 'start': 3016.852, 'duration': 3.229} {'text': 'and Serena Yeung who is\nup here in the front.', 'start': 3020.081, 'duration': 2.438} {'text': "We're both PHD students\nworking under Fei-Fei", 'start': 3022.519, 'duration': 2.7} {'text': 'on various computer vision problems.', 'start': 3025.219, 'duration': 2.16} {'text': 'We have an amazing\nteaching staff this year', 'start': 3027.379, 'duration': 2.617} {'text': 'of 18 TAs so far.', 'start': 3029.996, 'duration': 1.924} {'text': 'Many of whom are sitting\nover here in the front.', 'start': 3031.92, 'duration': 2.259} {'text': 'These guys are really the unsung heroes', 'start': 3034.179, 'duration': 1.742} {'text': 'behind the scenes making\nthe course run smoothly,', 'start': 3035.921, 'duration': 2.606} {'text': 'making sure everything happens well.', 'start': 3038.527, 'duration': 1.793} {'text': 'So be nice to them.', 'start': 3040.32, 'duration': 2.045} {'text': '[laughing]', 'start': 3042.365, 'duration': 1.831} {'text': 'I think I also should mention\nthis is the third time', 'start': 3044.196, 'duration': 2.957} {'text': "we've taught this course,\nand it's the first time", 'start': 3047.153, 'duration': 2.063} {'text': 'that Andrej Karpathy has\nnot been an instructor', 'start': 3049.216, 'duration': 2.436} {'text': 'in this course.', 'start': 3051.652, 'duration': 1.398} {'text': 'He was a very close friend of mine.', 'start': 3053.05, 'duration': 3.142} {'text': "He's still alive.", 'start': 3056.192, 'duration': 0.901} {'text': "He's okay, don't worry.", 'start': 3057.093, 'duration': 1.26} {'text': '[laughing]', 'start': 3058.353, 'duration': 1.259} {'text': "But, he graduated, so he's actually here", 'start': 3059.612, 'duration': 3.168} {'text': 'I think hanging around\nin the lecture hall.', 'start': 3062.78, 'duration': 2.944} {'text': 'A lot of the development and\nthe history of this course', 'start': 3065.724, 'duration': 1.938} {'text': 'is really due to him working on it', 'start': 3067.662, 'duration': 1.908} {'text': 'with me over the last couple of years.', 'start': 3069.57, 'duration': 2.047} {'text': 'So I think you should be aware of that.', 'start': 3071.617, 'duration': 3.781} {'text': 'Also about logistics,\nprobably the best way', 'start': 3075.398, 'duration': 2.796} {'text': 'for keeping in touch with the course staff', 'start': 3078.194, 'duration': 2.71} {'text': 'is through Piazza.', 'start': 3080.904, 'duration': 1.305} {'text': 'You should all go and signup right now.', 'start': 3082.209, 'duration': 3.003} {'text': 'Piazza is really our preferred\nmethod of communication', 'start': 3085.212, 'duration': 2.385} {'text': 'with the class with the teaching staff.', 'start': 3087.597, 'duration': 2.756} {'text': "If you have questions that you're afraid", 'start': 3090.353, 'duration': 2.268} {'text': 'of being embarrassed about asking', 'start': 3092.621, 'duration': 1.692} {'text': 'in front of your classmates, go ahead', 'start': 3094.313, 'duration': 1.754} {'text': 'and ask anonymously even\npost private questions', 'start': 3096.067, 'duration': 2.535} {'text': 'directly to the teaching staff.', 'start': 3098.602, 'duration': 1.97} {'text': 'So basically anything that you need', 'start': 3100.572, 'duration': 1.697} {'text': 'should ideally go through Piazza.', 'start': 3102.269, 'duration': 2.183} {'text': 'We also have a staff mailing list,', 'start': 3104.452, 'duration': 1.993} {'text': 'but we ask that this is mostly', 'start': 3106.445, 'duration': 1.977} {'text': 'for sort of personal, confidential things', 'start': 3108.422, 'duration': 2.88} {'text': "that you don't want going on Piazza,", 'start': 3111.302, 'duration': 2.215} {'text': "or if you have something\nthat's super confidential,", 'start': 3113.517, 'duration': 2.256} {'text': 'super personal, then feel free', 'start': 3115.773, 'duration': 2.592} {'text': 'to directly email me or\nFei-Fei or Serena about that.', 'start': 3118.365, 'duration': 3.76} {'text': 'But, for the most part,\nmost of your communication', 'start': 3122.125, 'duration': 1.775} {'text': 'with the staff should be through Piazza.', 'start': 3123.9, 'duration': 2.196} {'text': 'We also have an optional\ntextbook this year.', 'start': 3126.096, 'duration': 2.564} {'text': 'This is by no means required.', 'start': 3128.66, 'duration': 1.741} {'text': 'You can go through the course\ntotally fine without it.', 'start': 3130.401, 'duration': 2.215} {'text': 'Everything will be self contained.', 'start': 3132.616, 'duration': 1.756} {'text': "This is sort of exciting\nbecause it's maybe the first", 'start': 3134.372, 'duration': 3.398} {'text': 'textbook about deep\nlearning that got published', 'start': 3137.77, 'duration': 2.016} {'text': 'earlier this year by E.N. Goodfellow,', 'start': 3139.786, 'duration': 2.103} {'text': 'Yoshua Bengio, and Aaron Courville.', 'start': 3141.889, 'duration': 2.189} {'text': 'I put the Amazon link here in the slides.', 'start': 3144.078, 'duration': 2.606} {'text': 'You can get it if you want to,', 'start': 3146.684, 'duration': 1.513} {'text': 'but also the whole content of the book', 'start': 3148.197, 'duration': 1.882} {'text': "is free online, so you\ndon't even have to buy it", 'start': 3150.079, 'duration': 1.728} {'text': "if you don't want to.", 'start': 3151.807, 'duration': 1.136} {'text': 'So again, this is totally optional,', 'start': 3152.943, 'duration': 1.318} {'text': "but we'll probably be\nposting some readings", 'start': 3154.261, 'duration': 1.517} {'text': 'throughout the quarter\nthat give you an additional', 'start': 3155.778, 'duration': 1.836} {'text': 'perspective on some of the material.', 'start': 3157.614, 'duration': 3.0} {'text': 'So our philosophy about this class', 'start': 3161.697, 'duration': 1.562} {'text': 'is that you should really\nunderstand the deep mechanics', 'start': 3163.259, 'duration': 3.776} {'text': 'of all of these algorithms.', 'start': 3167.035, 'duration': 1.759} {'text': 'You should understand at a very deep level', 'start': 3168.794, 'duration': 1.877} {'text': 'exactly how these algorithms are working', 'start': 3170.671, 'duration': 2.046} {'text': "like what exactly is going on when you're", 'start': 3172.717, 'duration': 1.578} {'text': 'stitching together these neural networks,', 'start': 3174.295, 'duration': 1.802} {'text': 'how do these architectural decisions', 'start': 3176.097, 'duration': 2.031} {'text': 'influence how the network is trained', 'start': 3178.128, 'duration': 2.016} {'text': 'and tested and whatnot and all that.', 'start': 3180.144, 'duration': 2.17} {'text': 'And, throughout the course\nthrough the assignments,', 'start': 3182.314, 'duration': 2.897} {'text': "you'll be implementing\nyour own convolutional", 'start': 3185.211, 'duration': 1.952} {'text': 'neural networks from scratch in Python.', 'start': 3187.163, 'duration': 1.594} {'text': "You'll be implementing the\nfull forward and backward", 'start': 3188.757, 'duration': 2.803} {'text': 'passes through these\nthings, and by the end,', 'start': 3191.56, 'duration': 1.7} {'text': "you'll have implemented a whole\nconvolutional neural network", 'start': 3193.26, 'duration': 1.846} {'text': 'totally on your own.', 'start': 3195.106, 'duration': 1.214} {'text': "I think that's really cool.", 'start': 3196.32, 'duration': 2.0} {'text': 'But, we also kind of\npractical, and we know', 'start': 3198.32, 'duration': 2.249} {'text': 'that in most cases people\nare not writing these things', 'start': 3200.569, 'duration': 2.951} {'text': 'from scratch, so we also want to give you', 'start': 3203.52, 'duration': 2.093} {'text': 'a good introduction to some\nof the state of the art', 'start': 3205.613, 'duration': 2.156} {'text': 'software tools that are used\nin practice for these things.', 'start': 3207.769, 'duration': 3.557} {'text': "So we're going to talk about\nsome of the state of the art", 'start': 3211.326, 'duration': 2.047} {'text': 'software packages like Tensor\nFlow, Torch, [Py]Torch,', 'start': 3213.373, 'duration': 3.019} {'text': 'all these other things.', 'start': 3216.392, 'duration': 1.271} {'text': "And, I think you'll get some exposure", 'start': 3217.663, 'duration': 2.227} {'text': 'to those on the homeworks\nand definitely through', 'start': 3219.89, 'duration': 2.746} {'text': 'the course project as well.', 'start': 3222.636, 'duration': 1.892} {'text': 'Another note about this course', 'start': 3224.528, 'duration': 1.775} {'text': "is that it's very state of the art.", 'start': 3226.303, 'duration': 1.517} {'text': "I think it's super exciting.", 'start': 3227.82, 'duration': 1.302} {'text': 'This is a very fast moving field.', 'start': 3229.122, 'duration': 1.593} {'text': 'As you saw, even these plots\nin the imaging challenge', 'start': 3230.715, 'duration': 2.622} {'text': "basically there's been a ton of progress", 'start': 3233.337, 'duration': 2.274} {'text': "since 2012, and like while\nI've been in grad school,", 'start': 3235.611, 'duration': 3.229} {'text': 'the whole field is sort\nof transforming ever year.', 'start': 3238.84, 'duration': 1.698} {'text': "And, that's super exciting\nand super encouraging.", 'start': 3240.538, 'duration': 3.211} {'text': "But, what that means is that\nthere's probably content", 'start': 3243.749, 'duration': 3.428} {'text': "that we'll cover this\nyear that did not exist", 'start': 3247.177, 'duration': 1.955} {'text': 'the last time that this\ncourse was taught last year.', 'start': 3249.132, 'duration': 3.761} {'text': "I think that's super\nexciting, and that's one", 'start': 3252.893, 'duration': 1.524} {'text': 'of my favorite parts\nabout teaching this course', 'start': 3254.417, 'duration': 2.212} {'text': 'is just roping in all\nthese new scientific,', 'start': 3256.629, 'duration': 2.197} {'text': 'hot off the presses stuff and being able', 'start': 3258.826, 'duration': 2.215} {'text': 'to present it to you guys.', 'start': 3261.041, 'duration': 3.0} {'text': "We're also sort of about fun.", 'start': 3264.041, 'duration': 2.03} {'text': "So we're going to talk\nabout some interesting", 'start': 3266.071, 'duration': 1.699} {'text': 'maybe not so serious\ntopics as well this quarter', 'start': 3267.77, 'duration': 2.683} {'text': 'including image captioning is pretty fun', 'start': 3270.453, 'duration': 2.669} {'text': 'where we can write\ndescriptions about images.', 'start': 3273.122, 'duration': 2.227} {'text': "But, we'll also cover some\nof these more artistic things", 'start': 3275.349, 'duration': 1.828} {'text': 'like DeepDream here on the left', 'start': 3277.177, 'duration': 2.719} {'text': 'where we can use neural\nnetworks to hallucinate', 'start': 3279.896, 'duration': 2.365} {'text': 'these crazy, psychedelic images.', 'start': 3282.261, 'duration': 2.016} {'text': "And, by the end of the course, you'll know", 'start': 3284.277, 'duration': 1.698} {'text': 'how that works.', 'start': 3285.975, 'duration': 0.902} {'text': 'Or on the right, this\nidea of style transfer', 'start': 3286.877, 'duration': 2.023} {'text': 'where we can take an image and render it', 'start': 3288.9, 'duration': 1.728} {'text': 'in the style of famous artists\nlike Picasso or Van Gogh', 'start': 3290.628, 'duration': 3.879} {'text': 'or what not.', 'start': 3294.507, 'duration': 0.833} {'text': 'And again, by the end of the quarter,', 'start': 3295.34, 'duration': 1.314} {'text': "you'll see how this stuff works.", 'start': 3296.654, 'duration': 3.0} {'text': "So the way the course works\nis we're going to have", 'start': 3299.654, 'duration': 2.865} {'text': 'three problem sets.', 'start': 3302.519, 'duration': 1.275} {'text': 'The first problem set\nwill hopefully be out', 'start': 3303.794, 'duration': 3.245} {'text': 'by the end of the week.', 'start': 3307.039, 'duration': 1.213} {'text': "We'll have an in class,\nwritten midterm exam.", 'start': 3308.252, 'duration': 2.454} {'text': 'And, a large portion of your grade', 'start': 3310.706, 'duration': 1.805} {'text': "will be the final course\nproject where you'll work", 'start': 3312.511, 'duration': 2.545} {'text': 'in teams of one to three and produce', 'start': 3315.056, 'duration': 2.351} {'text': "some amazing project that\nwill blow everyone's minds.", 'start': 3317.407, 'duration': 3.107} {'text': 'We have a late policy, so\nyou have seven late days', 'start': 3320.514, 'duration': 3.357} {'text': "that you're free to allocate\namong your different homeworks.", 'start': 3323.871, 'duration': 2.509} {'text': 'These are meant to cover\nthings like minor illnesses', 'start': 3326.38, 'duration': 3.169} {'text': 'or traveling or conferences\nor anything like that.', 'start': 3329.549, 'duration': 4.655} {'text': 'If you come to us at\nthe end of the quarter', 'start': 3334.204, 'duration': 1.984} {'text': 'and say that, "I suddenly\nhave to give a presentation', 'start': 3336.188, 'duration': 2.569} {'text': '"at this conference."', 'start': 3338.757, 'duration': 1.214} {'text': "That's not going to be okay.", 'start': 3339.971, 'duration': 0.909} {'text': "That's what your late days are for.", 'start': 3340.88, 'duration': 1.744} {'text': 'That being said, if you have some', 'start': 3342.624, 'duration': 1.487} {'text': 'very extenuating circumstances,\nthen do feel free', 'start': 3344.111, 'duration': 2.532} {'text': 'to email the course staff\nif you have some extreme', 'start': 3346.643, 'duration': 2.062} {'text': 'circumstances about that.', 'start': 3348.705, 'duration': 1.59} {'text': 'Finally, I want to make a note', 'start': 3350.295, 'duration': 2.109} {'text': 'about the collaboration policy.', 'start': 3352.404, 'duration': 1.773} {'text': 'As Stanford students,\nyou should all be aware', 'start': 3354.177, 'duration': 1.744} {'text': 'of the honor code that governs the way', 'start': 3355.921, 'duration': 2.468} {'text': 'that you should be collaborating\nand working together,', 'start': 3358.389, 'duration': 2.396} {'text': 'and we take this very seriously.', 'start': 3360.785, 'duration': 2.824} {'text': 'We encourage you to think very carefully', 'start': 3363.609, 'duration': 2.026} {'text': "about how you're\ncollaborating and making sure", 'start': 3365.635, 'duration': 1.985} {'text': "it's within the bounds of the honor code.", 'start': 3367.62, 'duration': 3.417} {'text': 'So in terms of prerequisites,\nI think the most important', 'start': 3372.304, 'duration': 2.074} {'text': 'is probably a deep familiarity with Python', 'start': 3374.378, 'duration': 3.114} {'text': 'because all of the programming assignments', 'start': 3377.492, 'duration': 2.589} {'text': 'will be in Python.', 'start': 3380.081, 'duration': 2.258} {'text': 'Some familiarity with C\nor C++ would be useful.', 'start': 3382.339, 'duration': 3.727} {'text': 'You will probably not\nbe writing any C or C++', 'start': 3386.066, 'duration': 3.288} {'text': "in this course, but as you're\nbrowsing through the source", 'start': 3389.354, 'duration': 2.351} {'text': 'code of these various software packages,', 'start': 3391.705, 'duration': 1.971} {'text': 'being able to read C++ code at least', 'start': 3393.676, 'duration': 2.246} {'text': 'is very useful for understanding\nhow these packages work.', 'start': 3395.922, 'duration': 3.957} {'text': 'We also assume that you\nknow what calculus is,', 'start': 3399.879, 'duration': 2.56} {'text': 'you know how to take derivatives\nall that sort of stuff.', 'start': 3402.439, 'duration': 2.532} {'text': 'We assume some linear algebra.', 'start': 3404.971, 'duration': 1.562} {'text': 'That you know what matrices are', 'start': 3406.533, 'duration': 1.346} {'text': 'and how to multiply them\nand stuff like that.', 'start': 3407.879, 'duration': 4.193} {'text': "We can't be teaching you how to take", 'start': 3412.072, 'duration': 1.588} {'text': 'like derivatives and stuff.', 'start': 3413.66, 'duration': 2.031} {'text': 'We also assume a little bit of knowledge', 'start': 3415.691, 'duration': 1.63} {'text': 'coming in of computer\nvision maybe at the level', 'start': 3417.321, 'duration': 2.5} {'text': 'of CS131 or 231a.', 'start': 3419.821, 'duration': 1.417} {'text': 'If you have taken those courses before,', 'start': 3422.367, 'duration': 1.556} {'text': "you'll be fine.", 'start': 3423.923, 'duration': 1.197} {'text': "If you haven't, I think\nyou'll be okay in this class,", 'start': 3425.12, 'duration': 2.227} {'text': 'but you might have a tiny\nbit of catching up to do.', 'start': 3427.347, 'duration': 2.506} {'text': "But, I think you'll probably be okay.", 'start': 3429.853, 'duration': 1.697} {'text': 'Those are not super strict prerequisites.', 'start': 3431.55, 'duration': 2.154} {'text': 'We also assume a little\nbit of background knowledge', 'start': 3433.704, 'duration': 3.26} {'text': 'about machine learning\nmaybe at the level of CS229.', 'start': 3436.964, 'duration': 3.576} {'text': 'But again, I think really\nimportant, key fundamental', 'start': 3440.54, 'duration': 3.016} {'text': "machine learning concepts\nwe'll reintroduce", 'start': 3443.556, 'duration': 2.167} {'text': 'as they come up and become important.', 'start': 3445.723, 'duration': 2.032} {'text': 'But, that being said, a\nfamiliarity with these things', 'start': 3447.755, 'duration': 2.161} {'text': 'will be helpful going forward.', 'start': 3449.916, 'duration': 2.5} {'text': 'So we have a course website.', 'start': 3454.774, 'duration': 1.272} {'text': 'Go check it out.', 'start': 3456.046, 'duration': 0.904} {'text': "There's a lot of information and links", 'start': 3456.95, 'duration': 1.353} {'text': 'and syllabus and all that.', 'start': 3458.303, 'duration': 1.439} {'text': "I think that's all that I\nreally want to cover today.", 'start': 3459.742, 'duration': 3.914} {'text': 'And, then later this week on Thursday,', 'start': 3463.656, 'duration': 2.501} {'text': "we'll really dive into our\nfirst learning algorithm", 'start': 3466.157, 'duration': 2.576} {'text': 'and start diving into the\ndetails of these things.', 'start': 3468.733, 'duration': 4.167}